{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "g6CgbhUrvbG5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VU4jJHIlvphP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"race.csv\",encoding='utf-8')\n",
        "#print(len(data))=70544\n",
        "y = data['record']\n",
        "X = data.loc[:, [\"code\",\"lane\",\"sex\",\"age\",\"jockey_w\",\"jockey\",\"dandivi\",\"yeondivi\"\n",
        "                    ,\"s1f\",\"c3\",\"c4\",\"g3f\",\"g1f\",\"cure_in_1m\",\n",
        "                 \"weight_diff\",\"raw_weight\",\"weight_added\",\"prev1_velo\",\"horse_level_num\"]]\n",
        "#print(X.shape)\n",
        "sex_mod = pd.get_dummies(X['sex'])\n",
        "X = X.join(sex_mod)\n",
        "X = X.drop(columns=['sex'])\n",
        "#print(X.columns)\n",
        "X = X.as_matrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "akNj9hoTw707",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e96b4245-5e82-4a55-8c58-b8e5e475d6e4"
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "train_size = len(X_train)\n",
        "print(\"trains_size : \",train_size)\n",
        "size_x = len(X_train[0])\n",
        "print(\"size_x : \",size_x)\n",
        "learning_rate = 0.001\n",
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "print(X_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trains_size :  49380\n",
            "size_x :  21\n",
            "[[3.5223e+04 6.0000e+00 3.0000e+00 ... 1.0000e+00 0.0000e+00 0.0000e+00]\n",
            " [2.8232e+04 3.0000e+00 4.0000e+00 ... 0.0000e+00 0.0000e+00 1.0000e+00]\n",
            " [3.5892e+04 1.0000e+01 4.0000e+00 ... 0.0000e+00 0.0000e+00 1.0000e+00]\n",
            " ...\n",
            " [3.2214e+04 1.0000e+01 4.0000e+00 ... 0.0000e+00 0.0000e+00 1.0000e+00]\n",
            " [2.5347e+04 2.0000e+00 6.0000e+00 ... 0.0000e+00 1.0000e+00 0.0000e+00]\n",
            " [2.8625e+04 1.0000e+00 4.0000e+00 ... 1.0000e+00 0.0000e+00 0.0000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PnTPAT_Ez9La",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, size_x])\n",
        "Y = tf.placeholder(tf.float32, [None, 1])\n",
        "\n",
        "\n",
        "W1 = tf.get_variable(shape=[size_x, 256], name='weight1', initializer=tf.contrib.layers.xavier_initializer())\n",
        "b1 = tf.Variable(tf.random_normal([256]))\n",
        "layer1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
        "\n",
        "\n",
        "W2 = tf.get_variable(shape=[256, 64], name='weight2', initializer=tf.contrib.layers.xavier_initializer())\n",
        "b2 = tf.Variable(tf.random_normal([128]))\n",
        "layer2 = tf.nn.relu(tf.matmul(layer1, W2) + b2)\n",
        "\n",
        "\n",
        "W3 = tf.get_variable(shape=[64, 1], name='weight4', initializer=tf.contrib.layers.xavier_initializer())\n",
        "b3 = tf.Variable(tf.random_normal([1]))\n",
        "hypothesis = tf.matmul(layer2, W3) + b3\n",
        "\n",
        "cost = tf.losses.mean_squared_error(labels=Y, predictions=hypothesis)\n",
        "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}