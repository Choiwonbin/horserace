{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "g6CgbhUrvbG5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VU4jJHIlvphP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"race.csv\",encoding='utf-8')\n",
        "data = data.dropna(subset=['record'])\n",
        "# data = data.dropna() # 이거로 하면 cost 5자리수 나옴\n",
        "\n",
        "\n",
        "y = data['record']\n",
        "X = data.loc[:, [\"lane\",\"sex\",\"age\",\"jockey_w\",\"jockey\",\"dandivi\",\"yeondivi\",\"cure_in_1m\",\n",
        "                 \"weight_diff\",\"raw_weight\",\"weight_added\",\"prev1_velo\",\"horse_level_num\"]]\n",
        "\n",
        "#print(X.shape)\n",
        "\n",
        "# sex는 dummy 함수 처리\n",
        "sex_mod = pd.get_dummies(X['sex'])\n",
        "X = X.join(sex_mod)\n",
        "X = X.drop(columns=['sex'])\n",
        "#print(X.columns)\n",
        "X = X.as_matrix()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "akNj9hoTw707",
        "colab_type": "code",
        "outputId": "d8801159-5697-49ed-b9b5-4a2a73d719f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "train_size = len(X_train)\n",
        "print(\"train_size : \",train_size)\n",
        "\n",
        "size_x = len(X_train[0])\n",
        "print(\"size_x : \",size_x)\n",
        "\n",
        "# 설정하는 부분\n",
        "learning_rate = 0.001\n",
        "training_epochs = 100\n",
        "batch_size = 16\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_size :  48596\n",
            "size_x :  15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PnTPAT_Ez9La",
        "colab_type": "code",
        "outputId": "0a84e9b3-31c1-49a7-e840-9b9d245710c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1832
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, size_x])\n",
        "Y = tf.placeholder(tf.float32, [None, 1])\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "\n",
        "\n",
        "W1 = tf.get_variable(shape=[size_x, 16], name='weight1', initializer=tf.contrib.layers.xavier_initializer())\n",
        "b1 = tf.Variable(tf.random_normal([16]))\n",
        "layer1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
        "layer1 = tf.nn.dropout(layer1, keep_prob=keep_prob)\n",
        "\n",
        "\n",
        "W2 = tf.get_variable(shape=[16, 16], name='weight2', initializer=tf.contrib.layers.xavier_initializer())\n",
        "b2 = tf.Variable(tf.random_normal([16]))\n",
        "layer2 = tf.nn.relu(tf.matmul(layer1, W2) + b2)\n",
        "layer2 = tf.nn.dropout(layer2, keep_prob=keep_prob)\n",
        "\n",
        "\n",
        "W3 = tf.get_variable(shape=[16, 1], name='weight3', initializer=tf.contrib.layers.xavier_initializer())\n",
        "b3 = tf.Variable(tf.random_normal([1]))\n",
        "hypothesis = tf.matmul(layer2, W3) + b3\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "#cost = tf.losses.mean_squared_error(labels=Y, predictions=hypothesis)\n",
        "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(train_size / batch_size)\n",
        "\n",
        "    for i in range(total_batch):\n",
        "        batch_xs = X_train[i*16:(i+1)*16]\n",
        "        batch_ys = y_train[i*16:(i+1)*16].reshape(16,1)\n",
        "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob:0.7}\n",
        "        c, _ = sess.run([cost, train], feed_dict=feed_dict)\n",
        "        avg_cost += c/total_batch\n",
        "        \n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost = 28094.859344171\n",
            "Epoch: 0002 cost = 1490.603507305\n",
            "Epoch: 0003 cost = 1160.870104195\n",
            "Epoch: 0004 cost = 1112.735124510\n",
            "Epoch: 0005 cost = 1048.184310119\n",
            "Epoch: 0006 cost = 965.798328665\n",
            "Epoch: 0007 cost = 899.348867759\n",
            "Epoch: 0008 cost = 863.745838355\n",
            "Epoch: 0009 cost = 841.462584982\n",
            "Epoch: 0010 cost = 820.512091593\n",
            "Epoch: 0011 cost = 783.939630382\n",
            "Epoch: 0012 cost = 753.501359575\n",
            "Epoch: 0013 cost = 725.837088242\n",
            "Epoch: 0014 cost = 711.526376578\n",
            "Epoch: 0015 cost = 681.193405388\n",
            "Epoch: 0016 cost = 660.277234467\n",
            "Epoch: 0017 cost = 640.147135057\n",
            "Epoch: 0018 cost = 620.714924890\n",
            "Epoch: 0019 cost = 598.821959047\n",
            "Epoch: 0020 cost = 581.655060392\n",
            "Epoch: 0021 cost = 568.612276752\n",
            "Epoch: 0022 cost = 553.008758100\n",
            "Epoch: 0023 cost = 532.610906463\n",
            "Epoch: 0024 cost = 520.938743805\n",
            "Epoch: 0025 cost = 509.705150261\n",
            "Epoch: 0026 cost = 496.308639574\n",
            "Epoch: 0027 cost = 479.701210846\n",
            "Epoch: 0028 cost = 473.791683990\n",
            "Epoch: 0029 cost = 463.873432020\n",
            "Epoch: 0030 cost = 450.863574380\n",
            "Epoch: 0031 cost = 442.735169266\n",
            "Epoch: 0032 cost = 435.486562285\n",
            "Epoch: 0033 cost = 422.617054582\n",
            "Epoch: 0034 cost = 420.814834625\n",
            "Epoch: 0035 cost = 412.742714540\n",
            "Epoch: 0036 cost = 405.715519656\n",
            "Epoch: 0037 cost = 401.391565404\n",
            "Epoch: 0038 cost = 396.854570047\n",
            "Epoch: 0039 cost = 391.391460198\n",
            "Epoch: 0040 cost = 390.784661957\n",
            "Epoch: 0041 cost = 386.582263327\n",
            "Epoch: 0042 cost = 380.948586018\n",
            "Epoch: 0043 cost = 378.536656284\n",
            "Epoch: 0044 cost = 376.211202653\n",
            "Epoch: 0045 cost = 371.731123175\n",
            "Epoch: 0046 cost = 371.800430921\n",
            "Epoch: 0047 cost = 369.554017400\n",
            "Epoch: 0048 cost = 366.548226011\n",
            "Epoch: 0049 cost = 365.222485271\n",
            "Epoch: 0050 cost = 362.801919256\n",
            "Epoch: 0051 cost = 363.003321742\n",
            "Epoch: 0052 cost = 361.518536795\n",
            "Epoch: 0053 cost = 359.944819400\n",
            "Epoch: 0054 cost = 359.536700309\n",
            "Epoch: 0055 cost = 359.177382946\n",
            "Epoch: 0056 cost = 357.491365436\n",
            "Epoch: 0057 cost = 357.897082729\n",
            "Epoch: 0058 cost = 356.452755503\n",
            "Epoch: 0059 cost = 356.116338600\n",
            "Epoch: 0060 cost = 355.124187324\n",
            "Epoch: 0061 cost = 355.482592813\n",
            "Epoch: 0062 cost = 355.055283047\n",
            "Epoch: 0063 cost = 354.437086764\n",
            "Epoch: 0064 cost = 354.305392802\n",
            "Epoch: 0065 cost = 353.949261929\n",
            "Epoch: 0066 cost = 353.507349335\n",
            "Epoch: 0067 cost = 353.385108369\n",
            "Epoch: 0068 cost = 353.165239347\n",
            "Epoch: 0069 cost = 353.373787458\n",
            "Epoch: 0070 cost = 353.089693885\n",
            "Epoch: 0071 cost = 352.569805701\n",
            "Epoch: 0072 cost = 352.802074627\n",
            "Epoch: 0073 cost = 352.841499675\n",
            "Epoch: 0074 cost = 352.221158775\n",
            "Epoch: 0075 cost = 352.446321719\n",
            "Epoch: 0076 cost = 352.314673702\n",
            "Epoch: 0077 cost = 352.233171034\n",
            "Epoch: 0078 cost = 352.304477469\n",
            "Epoch: 0079 cost = 352.211124892\n",
            "Epoch: 0080 cost = 352.127353923\n",
            "Epoch: 0081 cost = 352.073542747\n",
            "Epoch: 0082 cost = 352.196396820\n",
            "Epoch: 0083 cost = 351.956495303\n",
            "Epoch: 0084 cost = 351.963015819\n",
            "Epoch: 0085 cost = 351.987284157\n",
            "Epoch: 0086 cost = 351.942001146\n",
            "Epoch: 0087 cost = 351.998518710\n",
            "Epoch: 0088 cost = 351.854756013\n",
            "Epoch: 0089 cost = 351.840291175\n",
            "Epoch: 0090 cost = 351.816221319\n",
            "Epoch: 0091 cost = 351.848534487\n",
            "Epoch: 0092 cost = 351.869676287\n",
            "Epoch: 0093 cost = 351.944693253\n",
            "Epoch: 0094 cost = 351.865788716\n",
            "Epoch: 0095 cost = 351.791053832\n",
            "Epoch: 0096 cost = 351.755814067\n",
            "Epoch: 0097 cost = 351.781991942\n",
            "Epoch: 0098 cost = 351.804540327\n",
            "Epoch: 0099 cost = 351.839538006\n",
            "Epoch: 0100 cost = 351.825458268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WCSnGM5rRFe_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "b6d61c08-ec3c-47c1-d7e7-998ed6438efb"
      },
      "cell_type": "code",
      "source": [
        "y_test = y_test.reshape(-1,1)\n",
        "\n",
        "acc = tf.equal(tf.argmax(hypothesis, axis=1), tf.argmax(Y, axis=1))\n",
        "accuracy = tf.reduce_mean(tf.cast(acc, tf.float32))\n",
        "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
        "      X: X_test, Y: y_test, keep_prob:1}))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XsXQbSlmkFoK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5202b1a4-cd6f-4a73-d11b-6adef755c165"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20828,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "GwgCBI49kX1m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}